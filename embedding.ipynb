{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gist.github.com/dirko/1d596ca757a541da96ac3caa6f291229\n",
    "\n",
    "http://dirko.github.io/Bidirectional-LSTMs-with-Keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author: Keras==1.0.6\n",
    "# mine: Keras==1.2.1\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import TimeDistributedDense, Activation\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.layers import Merge\n",
    "from keras.backend import tf\n",
    "from lambdawithmask import Lambda as MaskLambda\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode(x, n):\n",
    "    result = np.zeros(n)\n",
    "    result[x] = 1\n",
    "    return result\n",
    "\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "        \n",
    "def reverse_func(x, mask=None):\n",
    "    return tf.reverse(x, [False, True, False])\n",
    "\n",
    "def score(yh, pr):\n",
    "    coords = [np.where(yhh > 0)[0][0] for yhh in yh]\n",
    "    yh = [yhh[co:] for yhh, co in zip(yh, coords)]\n",
    "    ypr = [prr[co:] for prr, co in zip(pr, coords)]\n",
    "    fyh = [c for row in yh for c in row]\n",
    "    fpr = [c for row in ypr for c in row]\n",
    "    return fyh, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = open('train.csv', 'r').readlines()\n",
    "all_x = []\n",
    "point = []\n",
    "for line in raw:\n",
    "    stripped_line = line.strip().split(',')\n",
    "    point.append(stripped_line)\n",
    "    if line == '\"\"\\r\\n':\n",
    "#         print \"newline\"\n",
    "        all_x.append(point[:-1])\n",
    "        point = []\n",
    "all_x = all_x[:-1]\n",
    "lengths = [len(x) for x in all_x]\n",
    "# short_x = [x for x in all_x if len(x) < 64]\n",
    "short_x = []\n",
    "for l in all_x:\n",
    "    short_x.extend(chunks(l, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3428"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(short_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[c[0] for c in x] for x in short_x]\n",
    "y = [[c[1] for c in y] for y in short_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence length range:  4741 58\n"
     ]
    }
   ],
   "source": [
    "all_text = [c for x in X for c in x]\n",
    "words = list(set(all_text))\n",
    "word2ind = {word: index for index, word in enumerate(words)}\n",
    "ind2word = {index: word for index, word in enumerate(words)}\n",
    "labels = list(set([c for x in y for c in x]))\n",
    "label2ind = {label: (index + 1) for index, label in enumerate(labels)}\n",
    "ind2label = {(index + 1): label for index, label in enumerate(labels)}\n",
    "print 'Input sequence length range: ', max(lengths), min(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 64\n"
     ]
    }
   ],
   "source": [
    "maxlen = max([len(x) for x in X])\n",
    "print 'Maximum sequence length:', maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_enc = [[word2ind[c] for c in x] for x in X]\n",
    "X_enc_reverse = [[c for c in reversed(x)] for x in X_enc]\n",
    "max_label = max(label2ind.values()) + 1\n",
    "y_enc = [[0] * (maxlen - len(ey)) + [label2ind[c] for c in ey] for ey in y]\n",
    "y_enc = [[encode(c, max_label) for c in ey] for ey in y_enc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_enc_f = pad_sequences(X_enc, maxlen=maxlen)\n",
    "X_enc_b = pad_sequences(X_enc_reverse, maxlen=maxlen)\n",
    "y_enc = pad_sequences(y_enc, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing tensor shapes:\n",
      "(1440, 64) (352, 64) (1440, 64) (352, 64) (1440, 64, 8) (352, 64, 8)\n"
     ]
    }
   ],
   "source": [
    "(X_train_f, X_test_f, X_train_b,\n",
    " X_test_b, y_train, y_test) = train_test_split(X_enc_f, X_enc_b, y_enc,\n",
    "                                               test_size=11*32, train_size=45*32, random_state=42)\n",
    "print 'Training and testing tensor shapes:'\n",
    "print X_train_f.shape, X_test_f.shape, X_train_b.shape, X_test_b.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = len(word2ind)\n",
    "embedding_size = 128\n",
    "hidden_size = 32\n",
    "out_size = len(label2ind) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_forward = Sequential()\n",
    "model_forward.add(Embedding(max_features, embedding_size, input_length=maxlen, mask_zero=True))\n",
    "model_forward.add(LSTM(hidden_size, return_sequences=True))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_backward = Sequential()\n",
    "model_backward.add(Embedding(max_features, embedding_size, input_length=maxlen, mask_zero=True))\n",
    "model_backward.add(LSTM(hidden_size, return_sequences=True))\n",
    "model_backward.add(MaskLambda(function=reverse_func, mask_function=reverse_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jzhu/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:1205: UserWarning: `TimeDistributedDense` is deprecated, And will be removed on May 1st, 2017. Please use a `Dense` layer instead.\n",
      "  warnings.warn('`TimeDistributedDense` is deprecated, '\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Merge([model_forward, model_backward], mode='concat'))\n",
    "model.add(TimeDistributedDense(out_size))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 352 samples\n",
      "Epoch 1/40\n",
      "1440/1440 [==============================] - 14s - loss: 0.8888 - val_loss: 0.4311\n",
      "Epoch 2/40\n",
      "1440/1440 [==============================] - 12s - loss: 0.3824 - val_loss: 0.3680\n",
      "Epoch 3/40\n",
      "1440/1440 [==============================] - 11s - loss: 0.3041 - val_loss: 0.2703\n",
      "Epoch 4/40\n",
      "1440/1440 [==============================] - 13s - loss: 0.2087 - val_loss: 0.2094\n",
      "Epoch 5/40\n",
      "1440/1440 [==============================] - 12s - loss: 0.1538 - val_loss: 0.1828\n",
      "Epoch 6/40\n",
      "1440/1440 [==============================] - 12s - loss: 0.1247 - val_loss: 0.1695\n",
      "Epoch 7/40\n",
      "1440/1440 [==============================] - 11s - loss: 0.1062 - val_loss: 0.1589\n",
      "Epoch 8/40\n",
      "1440/1440 [==============================] - 11s - loss: 0.0928 - val_loss: 0.1590\n",
      "Epoch 9/40\n",
      "1440/1440 [==============================] - 10s - loss: 0.0819 - val_loss: 0.1506\n",
      "Epoch 10/40\n",
      "1440/1440 [==============================] - 10s - loss: 0.0733 - val_loss: 0.1473\n",
      "Epoch 11/40\n",
      "1440/1440 [==============================] - 11s - loss: 0.0668 - val_loss: 0.1445\n",
      "Epoch 12/40\n",
      "1440/1440 [==============================] - 12s - loss: 0.0618 - val_loss: 0.1465\n",
      "Epoch 13/40\n",
      "1440/1440 [==============================] - 11s - loss: 0.0577 - val_loss: 0.1429\n",
      "Epoch 14/40\n",
      "1440/1440 [==============================] - 11s - loss: 0.0539 - val_loss: 0.1426\n",
      "Epoch 15/40\n",
      "1440/1440 [==============================] - 13s - loss: 0.0508 - val_loss: 0.1452\n",
      "Epoch 16/40\n",
      "1440/1440 [==============================] - 11s - loss: 0.0479 - val_loss: 0.1442\n",
      "Epoch 17/40\n",
      "1440/1440 [==============================] - 10s - loss: 0.0455 - val_loss: 0.1450\n",
      "Epoch 18/40\n",
      "1440/1440 [==============================] - 11s - loss: 0.0434 - val_loss: 0.1439\n",
      "Epoch 19/40\n",
      "1440/1440 [==============================] - 12s - loss: 0.0415 - val_loss: 0.1433\n",
      "Epoch 20/40\n",
      "1440/1440 [==============================] - 11s - loss: 0.0399 - val_loss: 0.1442\n",
      "Epoch 21/40\n",
      "1440/1440 [==============================] - 10s - loss: 0.0384 - val_loss: 0.1455\n",
      "Epoch 22/40\n",
      "1440/1440 [==============================] - 12s - loss: 0.0372 - val_loss: 0.1430\n",
      "Epoch 23/40\n",
      "1440/1440 [==============================] - 12s - loss: 0.0361 - val_loss: 0.1506\n",
      "Epoch 24/40\n",
      "1440/1440 [==============================] - 12s - loss: 0.0348 - val_loss: 0.1451\n",
      "Epoch 25/40\n",
      "1440/1440 [==============================] - 11s - loss: 0.0337 - val_loss: 0.1525\n",
      "Epoch 26/40\n",
      "1440/1440 [==============================] - 11s - loss: 0.0328 - val_loss: 0.1489\n",
      "Epoch 27/40\n",
      "1440/1440 [==============================] - 11s - loss: 0.0317 - val_loss: 0.1479\n",
      "Epoch 28/40\n",
      "1440/1440 [==============================] - 11s - loss: 0.0308 - val_loss: 0.1516\n",
      "Epoch 29/40\n",
      "1440/1440 [==============================] - 11s - loss: 0.0299 - val_loss: 0.1497\n",
      "Epoch 30/40\n",
      "1440/1440 [==============================] - 11s - loss: 0.0292 - val_loss: 0.1503\n",
      "Epoch 31/40\n",
      "1440/1440 [==============================] - 11s - loss: 0.0284 - val_loss: 0.1508\n",
      "Epoch 32/40\n",
      "1440/1440 [==============================] - 11s - loss: 0.0276 - val_loss: 0.1494\n",
      "Epoch 33/40\n",
      "1440/1440 [==============================] - 11s - loss: 0.0270 - val_loss: 0.1533\n",
      "Epoch 34/40\n",
      "1440/1440 [==============================] - 11s - loss: 0.0263 - val_loss: 0.1517\n",
      "Epoch 35/40\n",
      "1440/1440 [==============================] - 11s - loss: 0.0255 - val_loss: 0.1548\n",
      "Epoch 36/40\n",
      "1440/1440 [==============================] - 11s - loss: 0.0249 - val_loss: 0.1522\n",
      "Epoch 37/40\n",
      "1440/1440 [==============================] - 11s - loss: 0.0243 - val_loss: 0.1563\n",
      "Epoch 38/40\n",
      "1440/1440 [==============================] - 12s - loss: 0.0237 - val_loss: 0.1567\n",
      "Epoch 39/40\n",
      "1440/1440 [==============================] - 11s - loss: 0.0231 - val_loss: 0.1537\n",
      "Epoch 40/40\n",
      "1440/1440 [==============================] - 11s - loss: 0.0225 - val_loss: 0.1536\n",
      "352/352 [==============================] - 0s     \n",
      "('Raw test score:', 0.15355714004148135)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit([X_train_f, X_train_b], y_train, batch_size=batch_size, nb_epoch=40,\n",
    "          validation_data=([X_test_f, X_test_b], y_test))\n",
    "score = model.evaluate([X_test_f, X_test_b], y_test, batch_size=batch_size)\n",
    "print('Raw test score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440/1440 [==============================] - 2s     \n",
      "Training accuracy: 0.999954909763\n",
      "Training confusion matrix:\n",
      "[[  371     0     2     0     0     0     0]\n",
      " [    0    41     1     0     0     0     0]\n",
      " [    0     0 82151     0     0     0     0]\n",
      " [    0     0     1    98     0     0     0]\n",
      " [    0     0     0     0    14     0     0]\n",
      " [    0     0     0     0     0   266     0]\n",
      " [    0     0     0     0     0     0  5766]]\n"
     ]
    }
   ],
   "source": [
    "pr = model.predict_classes([X_train_f, X_train_b])\n",
    "yh = y_train.argmax(2)\n",
    "fyh, fpr = score(yh, pr)\n",
    "print 'Training accuracy:', accuracy_score(fyh, fpr)\n",
    "print 'Training confusion matrix:'\n",
    "print confusion_matrix(fyh, fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 0s     \n",
      "Testing accuracy: 0.972151311209\n",
      "Testing confusion matrix:\n",
      "[[    0     0     0     0     0     0     0     0]\n",
      " [    0    53     0    22     0     0     0     7]\n",
      " [    0     0     2    11     0     0     0     0]\n",
      " [   19    17     0 19737     5     0    13   149]\n",
      " [    2     0     0    17    15     0     0     1]\n",
      " [    0     0     0     0     0     3     0     0]\n",
      " [    0     0     0    26     0     0    12     0]\n",
      " [   15     0     0   296     0     0     0  1123]]\n"
     ]
    }
   ],
   "source": [
    "pr = model.predict_classes([X_test_f, X_test_b])\n",
    "yh = y_test.argmax(2)\n",
    "fyh, fpr = score(yh, pr)\n",
    "print 'Testing accuracy:', accuracy_score(fyh, fpr)\n",
    "print 'Testing confusion matrix:'\n",
    "print confusion_matrix(fyh, fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
